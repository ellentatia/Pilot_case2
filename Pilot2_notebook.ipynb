{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>NLP Pilot  with values assessment - Identifying country names in the corpus of literature\n",
    "\n",
    "This is to briefly report on the work done for NLP Pilot 2 with the values assessment, Chapter 4, on the identification of country names from the corpus of selected literature. \n",
    "\n",
    "The aim was to prepare the Spatio-temporal representation of valuation studies related to biodiversity and ecosystem services: Atlas of Valuation.\n",
    "\n",
    "Input data: \n",
    "- Bib file downloaded from Web of Science \n",
    "- ISO 3166-1 alpha-3 country codes\n",
    "- IPBES regional and subregional country/area dataset\n",
    "\n",
    "Methods:\n",
    "- Python \n",
    "- Regular expression pattern and compiled strings match\n",
    "\n",
    "Outcome: \n",
    "- Identified country names in the title, abstract, and keywords, \n",
    "- Identified country names identified in the affiliations, acknowledgements and funding text \n",
    "- Corresponding IPBES region and subregions\n",
    "- The assessment experts are planning to use this information for a stratified sampling of the corpus for deep literature review, and for spatiotemporal analysis against gross domestic product and population.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Extracting country names from literature corpus"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import re \n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_table('IPBES_VA_Uptake_Corpus_06May20.txt', header=0)\n",
    "\n",
    "## open table and transform to dictionary for transforming country name to iso aplha3 code\n",
    "\n",
    "import csv\n",
    "\n",
    "dic = {}\n",
    "\n",
    "with open(\"wikipedia-iso-country-codes_05.csv\") as f:\n",
    "    file = csv.DictReader(f, delimiter=',')\n",
    "    for line in file:\n",
    "        dic[line['English short name lower case']] = line['Alpha-3 code']\n",
    "\n",
    "# list of countries from iso \n",
    "countries_list=[]\n",
    "for country in dic.keys():\n",
    "  countries_list.append(country)\n",
    "\n",
    "# function to extract countries and transform to iso alpha3 code        \n",
    "def extract(text):\n",
    "    data = str(text).replace(\".\", \" \").replace(\"-\", \" \").replace(\",\", \" \").replace(\";\", \" \").lower() \n",
    "    countries = re.compile(r'\\b(?:%s)\\b' % '|'.join([re.escape(x) for x in countries_list]),re.IGNORECASE) #regular expression\n",
    "    #print(countries)\n",
    "    result=countries.findall(data)\n",
    "    #return result\n",
    "    code = []\n",
    "    for country in dic.keys():\n",
    "      if  country.lower() in result:\n",
    "        code.append(dic[country])\n",
    "    return code      \n",
    "\n",
    "# function to filter repeated values\n",
    "def my_function(i):\n",
    "    return list(dict.fromkeys(i))\n",
    "# from list to strings\n",
    "\n",
    "def mystrings(text):\n",
    "    return ', '.join(text)\n",
    "    \n",
    "\n",
    "## columns to feed country1\n",
    "df['title_country'] = df.TI.map(extract)\n",
    "df['abstract_country'] = df.AB.map(extract)\n",
    "#print(df['title_country'])\n",
    "df['keywords_country'] = df.DE.map(extract)\n",
    "df['keywords-plus_country'] = df.ID.map(extract)\n",
    "\n",
    "df['countryname1'] = df['title_country'] + df['abstract_country'] + df['keywords_country'] + df['keywords-plus_country']\n",
    "df['CountryName_TI_AB_DE_ID']=df['countryname1'].map(my_function).map(mystrings) \n",
    "\n",
    "## columns to feed country2\n",
    "df['affiliation_country'] = df.C1.map(extract)\n",
    "df['funding_country'] = df.FU.map(extract)\n",
    "df['funding-acknowledge_country'] = df.FX.map(extract)\n",
    "df['countryname2'] = df['affiliation_country'] + df['funding_country'] + df['funding-acknowledge_country']\n",
    "df['CountryName_C1_FU_FX'] = df['countryname2'].map(my_function).map(mystrings)\n",
    "#print(df['CountryName_C1_FU_FX'][0])\n",
    "\n",
    "df2 = df.drop(['countryname1', 'countryname2', 'title_country', 'abstract_country', 'keywords_country', 'keywords-plus_country',\n",
    "     'affiliation_country', 'funding_country', 'funding-acknowledge_country'], axis=1)\n",
    "\n",
    "df2 = df2.reset_index(drop=True)\n",
    "# print(df2.columns)\n",
    "\n",
    "df2.to_csv('Pilot_case2_06.csv',index=False)\n",
    "df2.to_excel('Pilot_case2_06.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2: Bundle countries in regions"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#used the outcome from the code ellen_test50.py \n",
    "# objective to extract region based on the file final_land_vs1.csv \n",
    "\n",
    "import pandas as pd\n",
    "#df = pd.read_csv('Pilot_case2_05.csv', header=0)\n",
    "df = pd.read_csv('~/pilot2_re/Pilot_case2_06.csv', header=0) #25.06.2020\n",
    "# index_col=False)\n",
    "\n",
    "\n",
    "import csv\n",
    "\n",
    "dic = {}\n",
    "\n",
    "with open(\"final_land_vs1.csv\") as f:\n",
    "    file = csv.DictReader(f, delimiter=',')\n",
    "    for line in file:\n",
    "        dic[line['ISO_Alpha_3']] = line['Region']\n",
    "        \n",
    "\n",
    "def getRegion(text):\n",
    "    region = []\n",
    "    for country in dic.keys():\n",
    "      if str(country) in str(text):\n",
    "        region.append(dic[country])\n",
    "            \n",
    "    return region\n",
    "######\n",
    "\n",
    "# function to filter repeated values\n",
    "\n",
    "def my_function(i):\n",
    "    return list(dict.fromkeys(i))\n",
    "\n",
    "\n",
    "# from list to strings\n",
    "def mystrings(text):\n",
    "    return ', '.join(text)\n",
    "\n",
    "\n",
    "# Region\n",
    "\n",
    "df['Region country1'] = df['CountryName_TI_AB_DE_ID'].map(getRegion)\n",
    "df['Region country1'] = df['Region country1'].map(my_function).map(mystrings)\n",
    "df['Region country2'] = df['CountryName_C1_FU_FX'].map(getRegion)\n",
    "df['Region country2'] = df['Region country2'].map(my_function).map(mystrings)\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "print(df.columns)\n",
    "\n",
    "df.to_csv('Pilot_case2_region.csv',index=False)\n",
    "df.to_excel('Pilot_case2_region.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step3: Bundle countries in subregions"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "#df = pd.read_csv('Pilot_case2_08.csv', header=0)\n",
    "df = pd.read_csv('Pilot_case2_region.csv', header=0)\n",
    "# index_col=False)\n",
    "\n",
    "\n",
    "import csv\n",
    "\n",
    "dic = {}\n",
    "\n",
    "with open(\"final_land_vs1.csv\") as f:\n",
    "    file = csv.DictReader(f, delimiter=',')\n",
    "    for line in file:\n",
    "        dic[line['ISO_Alpha_3']] = line['Sub-Region']\n",
    "\n",
    "def getSubregion(text):\n",
    "    subregion = []\n",
    "    for country in dic.keys():\n",
    "      if str(country) in str(text):\n",
    "        subregion.append(dic[country])\n",
    "            \n",
    "    return subregion\n",
    "######\n",
    "\n",
    "def my_function(i):\n",
    "    return list(dict.fromkeys(i))\n",
    "\n",
    "\n",
    "# from list to strings\n",
    "def mystrings(text):\n",
    "    return ', '.join(text)\n",
    "\n",
    "# Sub-Region\n",
    "\n",
    "df['Sub-Region country1'] = df['CountryName_TI_AB_DE_ID'].map(getSubregion)\n",
    "df['Sub-Region country1'] = df['Sub-Region country1'].map(my_function).map(mystrings)\n",
    "#print(getSubregion(df['country name1'][0]))\n",
    "df['Sub-Region country2'] = df['CountryName_C1_FU_FX'].map(getSubregion)\n",
    "df['Sub-Region country2'] = df['Sub-Region country2'].map(my_function).map(mystrings)\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "print(df.columns)\n",
    "\n",
    "df.to_csv('Pilot_case2_region_subregion.csv',index=False)\n",
    "df.to_excel('Pilot_case2_region_subregion.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step4:Find TS accordinly"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "#df_total = pd.read_table('IPBES_VA_Uptake_Corpus_06May20.txt', header=0)\n",
    "\n",
    "df = pd.read_csv('Pilot_case2_region_subregion.csv', header=0,low_memory=False)\n",
    "#df=df_total.iloc[:100,:].copy()\n",
    "#df.fillna('', inplace=True)\n",
    "\n",
    "df_2 = pd.read_csv('2.csv', header=0,low_memory=False)\n",
    "df_3 = pd.read_csv('3.csv', header=0,low_memory=False)\n",
    "df_4 = pd.read_csv('4.csv', header=0,low_memory=False)\n",
    "df_5 = pd.read_csv('5.csv', header=0,low_memory=False)\n",
    "df_6 = pd.read_csv('6.csv', header=0,low_memory=False)\n",
    "df_7 = pd.read_csv('7.csv', header=0,low_memory=False)\n",
    "df_8 = pd.read_csv('8.csv', header=0,low_memory=False)\n",
    "df_9 = pd.read_csv('9.csv', header=0,low_memory=False)\n",
    "df_10 = pd.read_csv('10.csv', header=0,low_memory=False)\n",
    "df_11 = pd.read_csv('11.csv', header=0,low_memory=False)\n",
    "df_12 = pd.read_csv('12.csv', header=0,low_memory=False)\n",
    "df_13 = pd.read_csv('13.csv', header=0,low_memory=False)\n",
    "df_14 = pd.read_csv('14.csv', header=0,low_memory=False)\n",
    "df_15 = pd.read_csv('15.csv', header=0,low_memory=False)\n",
    "df_17 = pd.read_table('27NOT17.txt', header=0,low_memory=False)\n",
    "df_18 = pd.read_table('18.txt', header=0,low_memory=False)\n",
    "df_19 = pd.read_table('19.txt', header=0,low_memory=False)\n",
    "df_20 = pd.read_table('20.txt', header=0,low_memory=False)\n",
    "df_21 = pd.read_table('21.txt', header=0,low_memory=False)\n",
    "df_22 = pd.read_table('22_AN.txt', header=0,low_memory=False)\n",
    "df_23 = pd.read_table('23.txt', header=0,low_memory=False)\n",
    "df_24 = pd.read_table('24.txt', header=0,low_memory=False)\n",
    "df_25 = pd.read_table('25.txt', header=0,low_memory=False)\n",
    "df_26 = pd.read_table('26.txt', header=0,low_memory=False)\n",
    "#df_27 = pd.read_table('27NOT17.txt', header=0,low_memory=False)\n",
    "\n",
    "\n",
    "#df[TS1] all entries are 1\n",
    "value1=[]\n",
    "for x in range(0, len(df)):\n",
    "    value1.append(1)\n",
    "df['TS1']=value1\n",
    "\n",
    "\n",
    "def match(text):\n",
    "  # clean 4 digts\n",
    "  values=[]\n",
    "  for x in range(0, len(text)):\n",
    "    data=str(text[x])\n",
    "    values.append(data.replace(data[:4], 'ISI'))\n",
    "  # isin\n",
    "  A = df.UT.isin(values)\n",
    "  #return values\n",
    "  TSN=[]\n",
    "  for x in range(0, len(df)):\n",
    "    TSN.append(int(A[x]))\n",
    "  return TSN\n",
    "\n",
    "\n",
    "# apply match function to files 2 to 15\n",
    "\n",
    "df['TS2']= match(df_2['UT'])\n",
    "df['TS3']= match(df_3['UT'])\n",
    "df['TS4']= match(df_4['UT'])\n",
    "df['TS5']= match(df_5['UT'])\n",
    "df['TS6']= match(df_6['UT'])\n",
    "df['TS7']= match(df_7['UT'])\n",
    "df['TS8']= match(df_8['UT'])\n",
    "df['TS9']= match(df_9['UT'])\n",
    "df['TS10']= match(df_10['UT'])\n",
    "df['TS11']= match(df_11['UT'])\n",
    "df['TS12']= match(df_12['UT'])\n",
    "df['TS13']= match(df_13['UT'])\n",
    "df['TS14']= match(df_14['UT'])\n",
    "df['TS15']= match(df_15['UT'])\n",
    "\n",
    "\n",
    "#df[TS16] all entries are 1\n",
    "value16=[]\n",
    "for x in range(0, len(df)):\n",
    "    value16.append(1)\n",
    "df['TS16']=value16\n",
    "\n",
    "def clean_4digts(text):\n",
    "    values=[]\n",
    "    for x in range(0, len(text)):\n",
    "        data=str(text[x])\n",
    "        values.append(data.replace(data[:4], 'ISI'))\n",
    "    return values\n",
    "\n",
    "#df[TS17]\n",
    "value17=clean_4digts(df_17['UT'])\n",
    "df['ts17'] = df.UT.isin(value17)\n",
    "a=df['ts17']\n",
    "b=1-a\n",
    "df['TS17']=b\n",
    "\n",
    "\n",
    "df['TS18']= match(df_18['UT'])\n",
    "df['TS19']= match(df_19['UT'])\n",
    "df['TS20']= match(df_20['UT'])\n",
    "df['TS21']= match(df_21['UT'])\n",
    "df['TS22']= match(df_22['UT'])\n",
    "df['TS23']= match(df_23['UT'])\n",
    "df['TS24']= match(df_24['UT'])\n",
    "df['TS25']= match(df_25['UT'])\n",
    "df['TS26']= match(df_26['UT'])\n",
    "\n",
    "#value27 is 1\n",
    "value27=[]\n",
    "for x in range(0, len(df)):\n",
    "    value27.append(1)\n",
    "#print(value27[:5])\n",
    "df['TS27']=value27\n",
    "#print(df['TS27'][:5])\n",
    "\n",
    "df2= df.drop(['ts17'], axis=1)\n",
    "df2=df2.reset_index(drop=True)\n",
    "#print(df2.columns)\n",
    "#print(df2.head(2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b>Final outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_excel('Pilot_case2_region_subregion_TS.xlsx', index=False)\n",
    "df2.to_csv('Pilot_case2_region_subregion_TS.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
